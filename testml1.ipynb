{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+ZneQcutkgY0hpngJZHYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrhamtafere/colab-demo/blob/main/testml1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VV_H_QS3Sbc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238fe69d-42a5-4237-f22e-7ecc876f8d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am abrham and  \n"
          ]
        }
      ],
      "source": [
        "print(\"I am abrham and  \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the first programm')"
      ],
      "metadata": {
        "id": "KHRajoZoSfgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1c7eb1-8d66-46ba-cec9-d29eca9f0a6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first programm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "a5iJCKj33V0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Build a simple NLP Model that Predict Similar Words from Dataset you provide\n",
        "bold text# New Section"
      ],
      "metadata": {
        "id": "5NYu8Bp5KkCG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzPQwRJWS2eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1:\n",
        "Get the Text"
      ],
      "metadata": {
        "id": "cim-mqFkS341"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "WY9IibUzTHw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Machine_learning')\n",
        "article = scrapped_data .read()\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "metadata": {
        "id": "qWabl1AKTNzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_F1IXtlVTfcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2:\n",
        "Reomve Stop Words"
      ],
      "metadata": {
        "id": "dqjBMpwjTsNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import string\n",
        "    from nltk.corpus import stopwords\n",
        "    import nltk\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "class PreProcessText(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __remove_punctuation(self, text):\n",
        "        \"\"\"\n",
        "        Takes a String\n",
        "        return : Return a String\n",
        "        \"\"\"\n",
        "        message = []\n",
        "        for x in text:\n",
        "            if x in string.punctuation:\n",
        "                pass\n",
        "            else:\n",
        "                message.append(x)\n",
        "        message = ''.join(message)\n",
        "\n",
        "        return message\n",
        "\n",
        "    def __remove_stopwords(self, text):\n",
        "        \"\"\"\n",
        "        Takes a String\n",
        "        return List\n",
        "        \"\"\"\n",
        "        words= []\n",
        "        for x in text.split():\n",
        "\n",
        "            if x.lower() in stopwords.words('english'):\n",
        "                pass\n",
        "            else:\n",
        "                words.append(x)\n",
        "        return words\n",
        "\n",
        "\n",
        "    def token_words(self,text=''):\n",
        "        \"\"\"\n",
        "        Takes String\n",
        "        Return Token also called  list of words that is used to\n",
        "        Train the Model\n",
        "        \"\"\"\n",
        "        message = self.__remove_punctuation(text)\n",
        "        words = self.__remove_stopwords(message)\n",
        "        return words"
      ],
      "metadata": {
        "id": "kKO7mLDlTtcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "flag = nltk.download(\"stopwords\")\n",
        "\n",
        "if (flag == \"False\" or flag == False):\n",
        "    print(\"Failed to Download Stop Words\")\n",
        "else:\n",
        "    print(\"Downloaded Stop words ...... \")\n",
        "    helper = PreProcessText()\n",
        "    #words = helper.token_words(text=txt)\n",
        "    words = helper.token_words(text=article_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5LLYKbyVcO4",
        "outputId": "49f373f0-5249-4a6e-e657-81e4b9260fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Stop words ...... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "dqf7fA1LVgkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = Word2Vec([words], min_count=1)\n",
        "model = Word2Vec([words], window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "D7g1LgXNVtMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = model.wv.key_to_index"
      ],
      "metadata": {
        "id": "57Y1xEprVxKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "vocabulary = model.wv.key_to_index"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BXP4k6SJWjsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_words = model.wv.most_similar('machine')"
      ],
      "metadata": {
        "id": "v-MD201sWYrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZsQ76CTW5r9",
        "outputId": "497bb28a-892d-4dd3-ac95-f3a3bbd373a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('members', 0.35456305742263794),\n",
              " ('mathematically', 0.3324722349643707),\n",
              " ('Loss', 0.32221195101737976),\n",
              " ('Multilinear', 0.3118617832660675),\n",
              " ('Asian', 0.30812087655067444),\n",
              " ('boundary', 0.3073500692844391),\n",
              " ('demonstrated', 0.3016539216041565),\n",
              " ('scientific', 0.29843926429748535),\n",
              " ('playing', 0.2959069311618805),\n",
              " ('Machine', 0.2852904498577118)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = model[model.wv.vocab]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "kpxounICW7DN",
        "outputId": "924c9651-1d46-41fc-f199-f5f300d17ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c60322eee7e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Is6I8AkIW7dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AoV51OKJW7j7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}